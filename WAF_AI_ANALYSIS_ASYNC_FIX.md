# WAF AI Analysis - Corre√ß√£o Definitiva do Timeout 504

## üéØ Problema Real Identificado

**Erro:** 504 Gateway Timeout no endpoint `waf-dashboard-api`

**Causa Raiz REAL:**
- A a√ß√£o `ai-analysis` demora **32+ segundos** para completar
- Faz 10+ queries ao banco de dados para coletar dados
- Chama AWS Bedrock (Claude 3.5) que demora 20+ segundos
- API Gateway tem timeout de 30s ‚Üí Erro 504

**Logs comprovam:**
```
Duration: 32213.35 ms (32 segundos!)
Action: ai-analysis
Queries: 10+ COUNT(*) e GROUP BY
Bedrock call: ~20 segundos
```

## ‚úÖ Solu√ß√£o: Tornar AI Analysis Ass√≠ncrono

### Arquitetura Proposta

```
Frontend                    Lambda                      Bedrock
   |                          |                            |
   |--POST /ai-analysis------>|                            |
   |<-----job_id-------------|                            |
   |                          |                            |
   |                          |--Invoke Bedrock---------->|
   |                          |                            |
   |--GET /ai-status?id----->|                            |
   |<-----"processing"-------|                            |
   |                          |                            |
   |                          |<-----AI Response----------|
   |                          |                            |
   |--GET /ai-status?id----->|                            |
   |<-----"complete"+data----|                            |
```

### Implementa√ß√£o

#### 1. Modificar handleAiAnalysis para ser ass√≠ncrono

```typescript
/**
 * POST /waf-ai-analysis - Inicia an√°lise AI (ass√≠ncrono)
 * Retorna job_id imediatamente
 */
async function handleAiAnalysis(
  event: AuthorizedEvent,
  prisma: ReturnType<typeof getPrismaClient>,
  organizationId: string
): Promise<APIGatewayProxyResultV2> {
  logger.info('Starting async WAF AI analysis', { organizationId });
  
  // Criar job em background
  const job = await prisma.backgroundJob.create({
    data: {
      organization_id: organizationId,
      job_type: 'waf_ai_analysis',
      status: 'pending',
      created_at: new Date(),
    },
  });
  
  // Invocar Lambda ass√≠ncrona para processar
  const lambdaClient = new LambdaClient({ region: 'us-east-1' });
  await lambdaClient.send(new InvokeCommand({
    FunctionName: 'evo-uds-v3-production-waf-ai-analysis-worker',
    InvocationType: 'Event', // Ass√≠ncrono!
    Payload: JSON.stringify({
      jobId: job.id,
      organizationId,
    }),
  }));
  
  return success({
    jobId: job.id,
    status: 'processing',
    message: 'AI analysis started. Use GET /waf-ai-analysis-status?jobId=xxx to check progress.',
  });
}

/**
 * GET /waf-ai-analysis-status - Verifica status da an√°lise
 */
async function handleGetAiAnalysisStatus(
  event: AuthorizedEvent,
  prisma: ReturnType<typeof getPrismaClient>,
  organizationId: string
): Promise<APIGatewayProxyResultV2> {
  const params = event.queryStringParameters || {};
  const jobId = params.jobId;
  
  if (!jobId) {
    return error('jobId is required', 400);
  }
  
  const job = await prisma.backgroundJob.findFirst({
    where: {
      id: jobId,
      organization_id: organizationId,
    },
  });
  
  if (!job) {
    return error('Job not found', 404);
  }
  
  if (job.status === 'completed') {
    // Buscar an√°lise completa
    const analysis = await prisma.wafAiAnalysis.findFirst({
      where: {
        organization_id: organizationId,
      },
      orderBy: { created_at: 'desc' },
    });
    
    return success({
      status: 'completed',
      analysis: analysis?.analysis,
      context: analysis?.context,
      riskLevel: analysis?.risk_level,
      completedAt: job.completed_at,
    });
  }
  
  if (job.status === 'failed') {
    return success({
      status: 'failed',
      error: job.error_message,
      failedAt: job.completed_at,
    });
  }
  
  return success({
    status: job.status,
    progress: job.progress || 0,
  });
}
```

#### 2. Criar Lambda Worker para processar AI Analysis

```typescript
/**
 * Lambda Worker: evo-uds-v3-production-waf-ai-analysis-worker
 * Processa an√°lise AI em background (sem timeout do API Gateway)
 */
export async function handler(event: any) {
  const { jobId, organizationId } = event;
  const prisma = getPrismaClient();
  
  try {
    // Atualizar status para processing
    await prisma.backgroundJob.update({
      where: { id: jobId },
      data: { status: 'processing', started_at: new Date() },
    });
    
    // Executar an√°lise AI (pode demorar 30+ segundos, sem problema!)
    const result = await performAiAnalysis(prisma, organizationId);
    
    // Salvar resultado
    await prisma.wafAiAnalysis.create({
      data: {
        organization_id: organizationId,
        analysis: result.analysis,
        context: result.context,
        risk_level: result.riskLevel,
        ai_model: 'anthropic.claude-3-5-sonnet-20240620-v1:0',
        is_fallback: false,
      },
    });
    
    // Marcar job como completo
    await prisma.backgroundJob.update({
      where: { id: jobId },
      data: {
        status: 'completed',
        completed_at: new Date(),
        progress: 100,
      },
    });
    
    return { success: true };
    
  } catch (error) {
    // Marcar job como failed
    await prisma.backgroundJob.update({
      where: { id: jobId },
      data: {
        status: 'failed',
        completed_at: new Date(),
        error_message: error.message,
      },
    });
    
    throw error;
  } finally {
    await prisma.$disconnect();
  }
}
```

#### 3. Atualizar Frontend para polling

```typescript
// Frontend: src/hooks/useWafAiAnalysis.ts
export function useWafAiAnalysis() {
  const [status, setStatus] = useState<'idle' | 'processing' | 'completed' | 'failed'>('idle');
  const [analysis, setAnalysis] = useState<any>(null);
  const [jobId, setJobId] = useState<string | null>(null);
  
  // Iniciar an√°lise
  const startAnalysis = async () => {
    setStatus('processing');
    
    const response = await apiClient.invoke('waf-dashboard-api', {
      action: 'ai-analysis',
    });
    
    setJobId(response.jobId);
    
    // Iniciar polling
    pollStatus(response.jobId);
  };
  
  // Polling de status
  const pollStatus = async (jobId: string) => {
    const interval = setInterval(async () => {
      const response = await apiClient.invoke('waf-dashboard-api', {
        action: 'ai-analysis-status',
        jobId,
      });
      
      if (response.status === 'completed') {
        clearInterval(interval);
        setStatus('completed');
        setAnalysis(response.analysis);
      } else if (response.status === 'failed') {
        clearInterval(interval);
        setStatus('failed');
      }
    }, 2000); // Poll a cada 2 segundos
  };
  
  return { status, analysis, startAnalysis };
}
```

## üìä Benef√≠cios

### Antes (S√≠ncrono)
- ‚ùå Demora 32+ segundos
- ‚ùå Erro 504 Gateway Timeout
- ‚ùå Frontend travado esperando
- ‚ùå Usu√°rio n√£o sabe o que est√° acontecendo

### Depois (Ass√≠ncrono)
- ‚úÖ Resposta imediata (<100ms)
- ‚úÖ Sem erro 504
- ‚úÖ Frontend mostra progresso
- ‚úÖ Melhor UX com feedback visual

## üöÄ Implementa√ß√£o R√°pida (Alternativa Simples)

Se n√£o quiser criar Lambda Worker separada, pode usar a mesma Lambda com timeout maior:

```typescript
// Aumentar timeout da Lambda para 5 minutos
aws lambda update-function-configuration \
  --function-name evo-uds-v3-production-waf-dashboard-api \
  --timeout 300 \
  --region us-east-1

// Invocar de forma ass√≠ncrona
const lambdaClient = new LambdaClient({ region: 'us-east-1' });
await lambdaClient.send(new InvokeCommand({
  FunctionName: 'evo-uds-v3-production-waf-dashboard-api',
  InvocationType: 'Event', // Ass√≠ncrono!
  Payload: JSON.stringify({
    requestContext: { http: { method: 'POST' } },
    body: JSON.stringify({ action: 'ai-analysis-worker', organizationId }),
  }),
}));
```

## ‚úÖ Solu√ß√£o Imediata (Sem C√≥digo)

**Op√ß√£o 1:** Desabilitar AI Analysis temporariamente no frontend

**Op√ß√£o 2:** Aumentar timeout e usar cache:
```typescript
// Cache de 5 minutos para AI Analysis
const cacheKey = `waf:ai-analysis:${organizationId}`;
let cached = await redis.get(cacheKey);
if (cached) return success(JSON.parse(cached));

// Executar an√°lise
const result = await performAiAnalysis();

// Cachear por 5 minutos
await redis.setex(cacheKey, 300, JSON.stringify(result));
```

## üìù Status

- ‚úÖ Problema identificado: AI Analysis demora 32+ segundos
- ‚úÖ Causa raiz: 10+ queries + Bedrock call
- ‚è≥ Solu√ß√£o proposta: Tornar ass√≠ncrono
- ‚è≥ Implementa√ß√£o: Pendente

---

**Data:** 2026-01-15  
**Vers√£o:** 1.0  
**Prioridade:** ALTA - Bloqueia uso do WAF Dashboard
